---
title: |
  | What's the Half-Life of the Economic Vote?
  | (About a Year and a Half)\thanks{This article benefitted from much useful feedback. I owe particular thanks to X, Y, and Z. Thank you also to Richard McElreath who was kind enough to share the code necessary to make the equation labels that I use here.}
author: |
  | Jack Bailey,
  | The University of Manchester
date: |
  | \small This version: `r format(Sys.time(), '%B %d, %Y')`
  | Click \href{https://www.github.com/jackobailey/econ_half_life}{\textbf{here}} for replication materials.
abstract: |
  | One long-standing assumption dominates economic voting research: that voters are retrospective and myopic. Recent research attempts to test this assumption and to estimate a time frame for voters' economic perceptions. But the methods that this research uses face serious problems. To overcome this, I specify a new type of model that allows the economic vote to decay as voters' economic time frames increase. Consistent with voter myopia, I find that the economic vote is strongest where this time frame is shortest. After one and a half years, the economic voting effect falls by half. After five years, it becomes practically-equivalent to zero. This suggests two implications. First, that economic conditions at the time of the election matter most when it comes to deciding the incumbent's fate. Second, that governments receive undeserved leeway on economic policies that they implement early in their terms.
  |
  | \textsf{\textbf{Keywords:}} Economic voting; Retrospective voting; Bayesian methods.
indent: yes
fontsize: 12pt
geometry: margin = 1in
subparagraph: yes
compact-title: false
bibliography: _assets/master.bib
biblio-style: _assets/apsr.bst
classoption: a4paper
output: 
  bookdown::pdf_document2: 
    latex_engine: xelatex
    toc: false
    keep_tex: false
    includes:
      in_header:
        - _assets/rmd-preamble.tex
    number_sections: false
    fig_caption: true
---

\thispagestyle{empty}
\clearpage

\pagebreak

\setcounter{page}{1}

```{r setup, include = F}

# Load packages

library(kableExtra)
library(tidyverse)
library(magrittr)
library(jbmisc) # https://github.com/jackobailey/jbmisc
library(brms)
library(here)


# Load half-life model

m1 <- readRDS(here("_output", "m1.rds"))


# Estimate half-life distribution

half_life_dist <-
  log(2) %>% 
  divide_by(
    posterior_samples(
      m1,
      pars = "b_lambda"
    ) %>% 
      pluck(1)
  )


# Load figure scripts

source(here("_scripts", "003_gdp_plot.R"))
source(here("_scripts", "004_decay_plot.R"))
source(here("_scripts", "005_slope_plot.R"))
source(here("_scripts", "006_real_decay_plot.R"))
source(here("_scripts", "007_real_slope_plot.R"))


# Tell knitr to use Cairo PDF when rendering plots so that we get nice fonts

knitr::opts_chunk$set(dev = "cairo_pdf")

```

# Introduction

In 1992, MacKuen, Erikson, and Stimson argued that economic voting research had moved "little beyond introspection in understanding the processes by which citizens come to perceive economic movement" [@mackuen1992, p.597]. Three decades later, and we remain none the wiser. Just like the early-1990s, most economic voting scholars now believe that voters are both retrospective and myopic. And --- again like the early-1990s --- most economic voting scholars still do not know just *how retrospective* or *how myopic* these voters really are.

Instead, ad-hoc assumptions fill the void. As a result, the time frames that economic voting scholars expect voters to use vary from one study to the next. To appreciate the full range of assumptions on offer, consider the following examples. Some economic voting scholars assume that voters respond to economic change that takes place only in the year before an election [@bloom1975; @kramer1971]. Others, instead, assume that voters respond to the difference between the average economic growth in the first three quarters of the election year compared to the annual average of the previous year [@lewis-beck2013b]. Likewise, some assume that voters' economic perceptions come with a one year lead time [@dassonneville2017]. Others do not and assume instead that voters respond to simple year-on-year [@palmer2011; @clarke1986; @goodhart1970], quarter-on-quarter [@lanoue1987], or month-on-month [@lebo2007] changes in the state of the economy. Clearly, not all of these time frames can be correct at the same time.

To address this problem, I specify a new model that estimates both the economic vote and voter myopia at the same time. Data come from two sources. The first is individual-level voting intention data from the British Election Study Continuous Monitoring Survey. The second is aggregate-level economic statistics from the UK's Office for National Statistics. To model voter myopia, I rely on insights from the physical sciences. In particular, I borrow the concept of a "half-life" from biology and nuclear physics. Like a hour, a minute, or a second, a half-life is a unit of time. But unlike these measures it does not reflect a fixed interval. Rather, it reflects the average amount of time that it takes for a quantity to decay to half of its original value. Ordinarily, scientists would use the associated equation to estimate how much time it might take for radioactive decay to deplete the mass of a block of uranium or for the body's various physiological mechanisms to remove a dosage of a drug from a patient's body. That is to say, to estimate the half-life of a substance. Here, I use the equation to estimate the half-life of a parameter instead. Namely, the economic vote itself.

My findings are consistent with voter retrospection and voter myopia: voters respond most strongly to economic change in the recent past. As the time window between the past and the present increases, any economic voting effects being to peter out. After one and half years, they reach their half-life and fall to half of their initial strength. After five years, they become practically equivalent to zero. Consequently, we should not expect voters to judge governments based on the cumulative economic change during their time in office [@healy2014a; @hibbs2006]. Rather, we should expect them to judge governments based on the state of the economy when it comes time to vote.

These results suggest two implications. The first is that governments may receive undeserved leeway for any economic downturns that take place when they first come to power. Thus, the electoral consequences of poor economic management are likely to be small so long as it occurs far enough away from the next election. The second is that economic myopia might lead voters to opt not for the party best able to *manage* the economy, but instead the one best able to *manipulate* it. Governments might, therefore, seek to time economic rallies around election events to improve their chances of winning, rather than seek to manage the economy to the benefit of all citizens all of the time. That said, it remains possible that economic downturns might affect incumbent support in other ways. For example, they might still have long-term consequences where they condition voters' perceptions of party competence [@fieldhouse2020a].


# How Retrospective are Retrospective Voters?

It seems reasonable to expect voters to forget all sorts of details that political scientists might consider important. After all, voters often show little to no interest in politics [@zaller1992; @campbell1960], no one has a perfect memory, and to forget past events appears to be a fundamental aspect of how humans process information [@ariely2000].

Presumably, this is ever truer for complicated topics like the economy. Not only are there no end of important figures to keep track of, these figures also often change value, are subject to revision, and relate to one another in all manner of different ways. To make matters worse, most voters receive little to no formal education in economics. No wonder then that voters sometimes appear not to know what state the economy is really in [@paldam2000], at least not without a little help [@ansolabehere2013]. As a result, it would be very unusual if they were able to retain far-reaching and detailed memories of the economy's every ebb and flow.

Though the economic voting literature now spans more than 600 articles and books [@lewis-beck2017], little of this research investigates voter myopia. Instead, it glosses over it and simply assumes that voters have economic time frames of a year or less. The few pieces of research that do engage with this problem tend to do so in one of two ways: a voter-centric approach that relies on individual-level data and experimental methods or an electorate-centric approach that relies on aggregate-level time series data instead. Each has its own strengths and weaknesses, and comparing findings from one to the other can be difficult. Even so, they tend to come to the same conclusion: that voters' economic time frames are short. Still, how short remains in question.


## Voter-Centric Research

@stiers2019 provide a useful starting point as they are perhaps the only scholars to hold that voters are "attentive to the government’s performance in the long run as well as the short" (p.647). Their argument hinges on voter psychology. They claim that proponents of voter myopia make the implicit assumption that voters engage in memory-based information processing. Here, voters store information (e.g. economic conditions) in memory until such time as it is needed (e.g. to form an economic perception). As they note, storing such information over a government's entire term is clearly burdensome, to say the least. Instead, they contend that voters rely on online processing where they update they beliefs as though maintaining a running tally.

My own view is that it is unclear why information processing style should influence voter myopia. I make this point because retrospective voting under either memory-based or online processing requires exactly the same amount of information. A running tally is certainly more efficient than cataloguing events if one's intention is to maintain a belief about the *present* state of the economy. But that is not the task at hand. Instead, to "ascertain whether the incumbents have performed poorly or well, citizens need only calculate *the changes* in their own welfare" [@fiorina1981, p.5, emphasis own]. That is, voters must ask themselves the same question that Ronald Reagan posed during the 1980 US Presidential election campaign, “Are you better off than you were four years ago?". Note that this requires not one but two pieces of information: *present* and *past* conditions. Thus, voters must either retain two specific memories (if we assume memory-based processing) or instead two running tallies (if we assume online processing). As such, both approaches to information processing appear equally demanding.

@stiers2019 test their argument by using panel data from the Netherlands and the US to model incumbent voting as a function of voters' current and past satisfaction with the government in one model and their current and past satisfaction with the economy in another. Yet, again, these models do not reflect retrospective voting theory. To see why, consider the following simple retrospective voting model:

\begin{align*}
Vote_{i} &\sim \mathrm{Bernoulli}(\pi_{i}) \\
logit(\pi_{i}) &= \alpha + \beta (C_{0} - C_{t})
\end{align*}

Consistent with @fiorina1981, respondent $i$'s voting intention, Vote_{i}$, is a function of the difference between conditions now, $C_{0}$, and conditions at some point in the past, $C_{t}$^[Note that this is also the form that conventional economic voting models take. The only difference is that we measure $C_{0} - C_{t}$ using the standard retrospective voting question ("How do you think the *general economic situation in this country* has changed over the *last 12 months*?") and not two separate items that measure voters' perceptions of economic conditions now and in the past.]. That is to say, retrospective voting concerns *change*. @stiers2019, however, use a slightly different model as follows:

\begin{align*}
Vote_{i} &\sim \mathrm{Bernoulli}(\pi_{i}) \\
logit(\pi_{i}) &= \alpha + \beta_{1} C_{0} + \beta_{2} C_{t}
\end{align*}

The components here are the same as before. Yet now past and present conditions (in this case either satisfaction with the government or the economy) each have their own effect on support for the incumbent party. This is a problem. As $C_{0}$ and $C_{t}$ each have an independent effect on whether respondent $i$ votes for the incumbent, the model privileges the *level of* --- rather than the *change in* --- conditions. This is akin to assuming either that voters use a weighted average of past conditions when determining how to vote or that their past beliefs continue to have some effect on their voting behaviour that does not operate through their current beliefs^[It is worth nothing here that we also know that stable aspects of voters' personalities affect how they respond to these items [@conover1987] and that many attitudinal items exhibit trait-like stability [@kiley2020]. Thus, we cannot rule out the possibility that both current and past items really tap some stable latent trait or that they are not the product of multicollinearity problems.]. But as neither interpretation concerns change, the model has little to say about voter myopia.

The remaining voter-centric work on voter myopia relies on experimental methods. @huber2012, for example, note that psychological evidence suggests that people do not keep track of their utility over time. Rather, they use a heuristic called the "peak-end rule: they rate an experience based either on how it ended or how it was at its most intense [@ariely2000]. They specify an experimental game to test this in a retrospective voting setting where they vary when their subjects are made aware of the upcoming "election". They find that those subjects who became aware of the event later on tended also to overweight incumbent performance closer to the event.

@healy2014a conduct a similar study, again drawing on the peak-end rule for inspiration. Their design is particularly interesting as they allow their subjects to explain how they intend to weight the economy in each year of the incumbent's term before conducting their experiment. Consistent with @hibbs2006, their subjects say that they intend to judge the incumbent party based on the cumulative economic change over its entire term in office. Even so, just like @huber2012, @healy2014a show that their subjects instead "substitute the end for the whole". In other words, voters are myopic and focus most of their attention on election year performance.


## Electorate-Centric Research

Most electorate-centric research follows the precedent set by @hibbs1987 and focusses not only on how myopic voters are but also the functional form that their myopia takes. Hibbs' approach is as follows. First, he assumes that voters' memories decay at a known exponential rate. He then takes past estimates of year-on-year real income growth, weights them according to his exponential function, and  uses them to predict incumbent vote share across a range of US presidential elections. This, he claims, shows that voters are myopic. @achen2016 come to a similar conclusion using both the same approach as Hibbs and an even more limited one, which assumes that voters respond only to economic growth in the two quarters before an election.

@wlezien2015 argues that these approaches are overly-conservative and that the extent to which we consider the electorate to be myopic depends on the functional form that we assume their myopia to take. Rather than use an exponential weighting function like Hibbs, he uses a logistic one instead. Due to its shape, the logistic function is less conservative and allows voters' some time to reflect on the recent past. Wlezien's results indicate that voters are myopic, though less so than often thought: they do not respond to GDP growth at the very start of the incumbent's term, but they do respond to it over at least the past few years.

By and large, this research arrives at a conclusion that satisfies the assumptions that it makes about how voter myopia operates. Though this is perhaps unsurprising, it is a problem. Consider the equation below, which characterises this approach:

\begin{align*}
Vote_{i} &\sim \mathrm{Normal}(\mu_{i}, \sigma) \\
\mu_{i} &= \alpha + \sum_{q = 1}^{Q} \beta_{q} w_{q} (GDP_{q} - GDP_{q-4})
\end{align*}

Here, the incumbent party's vote share at election $i$, $Vote_{i}$, is equal to some constant, $\alpha$, plus the sum of the product of year-on-year change in GDP growth in quarter $q$, $GDP_{q} - GDP_{q-4}$, and the weight associated with that figure according to the chosen weighting function of choice, $w_{q}$.

This approach requires that we make two ad-hoc assumptions. The first and most obvious is that we must assume that voter myopia takes some particular form, whether exponential or otherwise. But to do so reliably requires some prior knowledge of how myopic voters really are. Of course, if this were possible then there would be no need to research voter myopia in the first place. The second is that these models force us to assume that voters in the present should care about GDP growth over the past year, but also, for example, between two years ago and one year ago. For the same reasons that I point out above, this does not reflect how retrospective voting theory really works. That is to say, we should not expect voters to care about lagged year-on-year GDP growth, but instead the difference between GDP now and at different points in the past.


## Towards a Hybrid Approach

I have hoped to show that while the research tends to find that voters are myopic, much uncertainty remains. Ultimately, this is because estimating voters' retrospective economic time frames is complex. Voter-centric approaches have had to deal with items that suffer from known biases [@conover1987] and experimental methods that may not generalise outside of the survey context [@barabas2010]. Likewise, electorate-centric approaches have had to rely on ad-hoc assumptions and suffer with problems of ecological inference [@stewart2017].

Thus, the most sensible way forward is perhaps to combine the strengths of each approach. That is, to make use of individual-level voting intention data, to avoid problems of ecological inference, and aggregate-level economic indicators, to avoid problems of bias. This hybrid approach is rare in the economic voting literature, where most research relies on cross-sectional surveys [though see @reidy2017]. Still, when paired with the appropriate methods, it offers the possibility of estimating voters' retrospective time frames in a way that avoids many of the prevailing assumptions.


# ... And Why Should We Care?

One obvious retort to the points I raise above is "so what?". After all, if voters engage in economic voting, does it really matter what time frame they use? The answer is simple enough: Yes, it does.

First, voters' economic time frames have clear policy implications. Or, as Tufte puts it, a shorter time frame would likely result in "myopic policies for myopic voters" [-@tufte1978, p.143]. Imagine a scenario where voters have short economic time frames and, more importantly, their government is aware of this fact. Under such a scenario, the incumbent can reasonably expect only to be punished for choices that fall within this short window of time. In effect, this incentivises governments to make any unpopular policy decisions early in their term, safe in the knowledge that voters will forget them. Likewise, it also incentivises them to make more popular policy decisions later in their term so that voters' perceptions of the party at the election are as positive as possible. In the extreme, where governments lack a clear policy agenda, or simply reach the point of desperation, profligacy is likely to be the end result. After all, uncosted or unaffordable tax cuts and spending pledges offer struggling governments a last-ditch hope at reelection and their consequences can be dealt at the start of the next term, which voters are likely to forget.

Second, myopic voters are prone to voting not for the best economic *manager* but instead for the best economic *manipulator*. Armed with the levers of the state, incumbent parties can and do use their power to shape voters preferences in their own favour [@dunleavy1981; @tufte1978]. Though this view is common in the economic voting literature [see @stegmaier2019; @stewart2017; @stegmaier2017; @lewis-beck2017], some doubt whether governments really have such a high degree of control over the state of the economy [@dynes2019]. Still, if we relax this assumption the results are not much better: we must accept that luck, not competence, decides elections [@achen2016; @wlezien2015]. Clearly, this is not a satisfactory outcome for democratic accountability.

Third, voter myopia disrupts the mechanism that retrospective voting theory assumes encourages accountability and improves economic outcomes. As @achen2016 argue, if elections are "referenda on the incumbent administration's handling of the economy" [@fiorina1981, p.26], then economic conditions should improve where voters reelect the incumbent. This is because the incumbent has, presumably, demonstrated that it provides better-than-average economic management. To make this decision, voters should make use of *all* available information on the incumbent's ability to manage the economy [@healy2014a; @hibbs2006]. If the information that they have access to covers only a small sliver of time close to the election, then this is simply not possible. No wonder then that there is little evidence that economic outcomes do improve where incumbents are reelected [@achen2016].


# Data

As I discuss above, I take a hybrid approach here that combines the strengths of the voter-centric and electorate-centric economic voting research. This requires two sources of information: individual-level voting intention data and aggregate-level economic statistics.

My individual-level voting intention data come from the British Election Study Continuous Monitoring Survey (CMS). The CMS comprises a series of monthly political surveys that took place in Great Britain between April 2004 and February 2014. The polling company YouGov administered the data collection process in all cases and the data were structured as a series of monthly repeated cross-sections. In total, 132,369 people took part in the CMS. To ensure that the data are representative, YouGov also weights each respondents according to both their past voting behaviour and their socio-demographic characteristics [@twyman2008].

My aggregate-level economic data come from the UK's Office for National Statistics (ONS). The ONS is the UK's national statistics body and is charged with producing and reporting a range of economic statistics including GDP, the rate of unemployment, and the level of inflation. In most cases, it does so on a quarterly basis, though the most popular indicators are often available as monthly time series too. The economic voting literature most often uses GDP as its indicator of choice. Indeed, some go so far as to call it "the most general objective measure of economic welfare" [@kayser2011, p. 376]. As such, I follow suit and use the ONS' time series of monthly UK GDP.


# Methods

Economic voting research that uses aggregate economic indicators faces a major constraint: the release schedule of the statistical agencies behind them. In most cases, these agencies release new data on a quarter-by-quarter, or even year-by-year, basis. This is of little use if your research question concerns much more granular time periods. Clearly, this is true in the present case.

To circumvent this problem, I use a two-stage approach. In the first stage, I produce a time series of daily GDP estimates for the UK from `r gdp$date %>% min() %>% format("%e %B %Y") %>% str_remove(" ")` to `r gdp$date %>% max() %>% format("%e %B %Y") %>% str_remove(" ")`. In the second stage, I link each of the individual respondents in the CMS to a random date up to five years before the date that they took their survey, then calculate GDP growth between the two time points. I then fit a model to these linked data that estimates both the economic vote and voter myopia at the same time.


## Stage 1: Estimating Daily GDP

```{r gdp-plot, fig.cap = "To estimate daily GDP, I fit a spline (*k* = 100) to monthly GDP data from the ONS. I then assign each case to a random date from up to 5 years ago and calculate GDP change between the two dates.", fig.width = 6, fig.height = 2.2, echo = F}
gdp_plot
```

Figure 1 shows the three steps that I take to estimate daily UK GDP. Each point in the left-most panel reflects a single estimate from the ONS' monthly time series of UK GDP. These begin in `r gdp$date %>% min() %>% format("%B %Y")`, end in `r gdp$date %>% max() %>% format("%B %Y")`, and are indexed such that July 2016 equals 100. Two patterns are most obvious. First, that UK GDP has tended to grow from one month to the next. Second, that the global financial crisis interrupted this process in the mid-2000s. GDP growth was faster before than after the financial crisis, on average. The rate of growth also appears to differ at different points in time.

The centre-most panel shows the same GDP estimates as the first, though a curve now runs through them. This reflects the average level of GDP across the time series and, due to its form, does not assume that UK GDP changes at a constant rate. To compute this curve, I fit a penalised cubic regression spline with 100 knots to the data. As we can see, the model fits well. Consequently, there is good reason to believe that any estimates that it produces should also reflect historic UK GDP.

The right-most panel shows how I put these estimates to use. The `r m1$data %>% nrow() %>% format(big.mark = ",")` respondents in the data took their survey on some day between 8 April 2004 and 2 February 2014. Imagine, for example, a respondent who took their survey in March 2013. I allocate this respondent to a random date up to five years before the date that they completed their survey, then calculate the time that has passed between the two points. Next, I use my penalised regression spline to estimate UK GDP on each day, then compute GDP growth between the two dates in percentage terms.


## Stage 2: Estimating Voters' Economic Time Frames

To specify a model that estimates both the economic vote and voter myopia requires considerable flexibility. Such flexibility is difficult to achieve using conventional Frequentist methods. To account for this, I fit my model using Bayesian methods instead. As the model is quite complex, the simplest way to explain it is to start with a simpler, more familiar, model and then build up each element of the model step-by-step. To this end, consider the simple retrospective voting model that I discussed above:

\begin{align*}
Vote_{i} &\sim \mathrm{Bernoulli}(\pi_{i}) \flab{Likelihood function}\\
logit(\pi_{i}) &= \alpha + \beta (C_{0} - C_{t}) \flab{Linear model on $\pi_{i}$}
\end{align*}

At present, the object of retrospection is some abstract condition, $C$. The first step in building the model is to replace this abstract condition with a more meaningful one: the change in the state of the economy. As I mentioned in the previous section, my measure of economic change is the percentage change in GDP between the date that each respondent took their survey and the random date to which I assigned them. As the CMS was collected on a monthly basis, there is likely some survey-specific variation to account for. To this end, I also include an adaptive prior on the intercept, $\alpha$, that allows it to vary from month to month:

\begin{align*}
Vote_{i} &\sim \mathrm{Bernoulli}(\pi_{i}) \flab{Likelihood function}\\
logit(\pi_{i}) &= \alpha_{\mathrm{wave}[i]} + \beta(\frac{\widehat{GDP_{0}} - \widehat{GDP_{t}}}{\widehat{GDP_{t}}} \times 100) \flab{Linear model on $\pi_{i}$}\\
\alpha_{\mathrm{wave}} &\sim \mathrm{Normal}(\overline{\alpha}, \sigma_{\alpha}) \flab{Adaptive prior on varying intercepts}\\
\overline{\alpha} &\sim \mathrm{Normal}(0, 1.5) \flab{Prior on grand mean of intercepts}\\
\sigma_{\alpha} &\sim \mathrm{Exponential}(5) \flab{Prior on standard deviation of intercepts}
\end{align*}

Note that the economic voting effect, $\beta$, is currently fixed for all values of $t$. No matter if I link the respondent to GDP change over the past five years or the past five days, the estimate remains fixed. But this makes little sense if voters are myopic. Instead, the economic voting effect should vary as a function of $t$. In particular, it should decay as $t$ increases to reflect the fact that people are more likely to forget events that took place a longer time ago.

One way to conceive of voter myopia is as a process of exponential decay^[This is similar to the approach that @hibbs1987 takes, and which I discuss above. Note, however, that unlike Hibbs, I do not fix the degree of exponential decay a-priori. Instead, I estimate it from the data.]. Where a quantity undergoes exponential decay, it begins at some initial value then diminishes quickly before levelling out as it approaches zero. Such processes are common in the physical sciences, where they are used to study the radioactive decay of chemical elements like iron or uranium or to estimate how long a quantity of some drug might spend in a patients body. I draw on these insights here and approximate voter myopia using the following equation taken from @rosch2014:

\begin{align*}
N(t) = N_{0}e^{-\lambda t}
\end{align*}

In this equation, $N(t)$ represents the quantity of some substance $N$ at time $t$. Where $t = 0$, the equation simplifies such that $N(t) = N_{0}$, the substance's initial quantity. As time passes, the substance decays subject to the "decay constant", $\lambda$. Further, the larger the value that the decay constant takes, the faster the substance decays. The amount of time that it takes for the substance to decay by half is known as its "half-life", $t_{1/2}$. For example, uranium-235, which powers most nuclear reactors, has a half-life of 703.8 million years. Likewise, the anti-inflammatory drug Ibuprofen has a half-life of two to four hours. Fortunately, as the decay constant, $\lambda$, and the half-life, $t_{1/2}$, share a close relationship, it is straight-forward to calculate one from the other:

```{r decay-plot, fig.cap = "The decay constant and half-life are related. When the former increases, the latter decreases. This is because the relationship between the two is deterministic. More specifically, t½ = log(2)/$\\lambda$.", fig.width = 6, fig.height = 2.3, echo = F}
decay_plot
```

\begin{align*}
t_{1/2} = \frac{log(2)}{\lambda}
\end{align*}

Of course, in this case, the quantity of interest is not really a substance like uranium or a drug like Ibuprofen. Instead, it is a parameter: the economic voting effect, $\beta$. Given this, substituting $N$ for $\beta$ allows the model to estimate the economic vote, but also allows it to vary according to the time interval $t$, consistent with voter myopia:

\begin{align*}
\beta_{t} = \beta_{0} e^{-\lambda t}
\end{align*}

At this point it is worth pausing for a moment and considering how the decay constant and half-life parameters relate to one another in greater detail. Figure \@ref(fig:decay-plot) shows how changes in former affect changes in the latter. Moving from the left-most to the right-most panel, the value that the decay constant takes increases from 0.25, to 0.5, to 0.75. As it does so, two things happen. First, the economic voting effect decays more quickly. Second, the value of the half-life parameter, $t_{1/2}$, decreases to account for the increased rate of decay.

```{r slope-plot, fig.cap = "The slope is related to the time interval. As the interval increases, the slope decays. In this simulated example, the slope at time 0 is held at 0.2 and the decay constant is held at 1.", fig.width = 6, fig.height = 2.3, echo = F}
slope_plot
```

Figure \@ref(fig:slope-plot) uses simulated data to show how this decay process affects the probability that a voter will vote for the incumbent across different time intervals. In the left-most panel, the time interval between the date that the respondent answered their survey and their random reference date is set to zero. In effect, the voter is evaluating the state of the economy in the immediate present. As such, the economic vote has undergone no exponential decay and remains at its initial value. In this scenario, there is a strong economic voting effect: as GDP change increases, voters become more likely to vote for the incumbent party. This is true also in the centre-most and right-most panels, though, in both cases, the economic voting effect diminishes due to voter myopia. In the centre-most panel, where the time interval equals one year, some effect persists, though it is now more modest than it was when the time interval was equal to zero. In the right-most panel, where the time interval now equals two years, the economic voting effect has decayed to such an extent that it is only slightly different to zero.

Substituting this exponential decay model into the retrospective voting model above gives the final model that I fit to my data. Note that I also include a set of covariates, $x$. These account for the passage of time, the different Prime Ministers in power over the course of this period, the amount of time that each leader spent in office, and the interaction between each leader and their time in office. Finally, as this is a Bayesian model, I must also include a prior distribution for each parameter in my model. In all cases, I use conservative and weakly informative priors that gently regularise my estimates. Given this, I specify the model that I fit to my data as follows:

\begin{align*}
Vote_{i} &\sim \mathrm{Bernoulli}(\pi_{i}) \flab{Likelihood function}\\
logit(\pi_{i}) &= \alpha_{\mathrm{wave}[i]} + \beta_{t}(\frac{\widehat{GDP_{0}} - \widehat{GDP_{t}}}{\widehat{GDP_{t}}} \times 100) + \sum_{j = 1}^{6} \delta_{j} x_{ji} \flab{Linear model on $\pi_{i}$}\\
\beta_{t} &= \beta_{0}e^{-\lambda t} \flab{Exponential decay model on $\beta_{t}$}\\
\alpha_{\mathrm{wave}} &\sim \mathrm{Normal}(\overline{\alpha}, \sigma_{\alpha}) \flab{Adaptive prior on varying intercepts}\\
\overline{\alpha} &\sim \mathrm{Normal}(0, 1.5) \flab{Prior on grand mean of intercepts}\\
\sigma_{\alpha} &\sim \mathrm{Exponential}(5) \flab{Prior on standard deviation of intercepts}\\
\beta_{0} &\sim \mathrm{Normal}(0, 0.5) \flab{Prior on $\beta$ where $t$ = 0}\\
\delta_{j} &\sim \mathrm{Normal}(0, 0.5) \flab{Prior on $\delta$ parameters} \text{ for } j \text{ in } 1..J\\
\lambda &\sim \mathrm{Normal}(0, 0.5) \flab{Prior on the decay constant, $\lambda$}
\end{align*}


# Results

Table 1 shows the resulting parameter estimates from the fitted model. In all cases, coefficients show the expected relationships. Consider first the chief variable of interest: GDP change at $t = 0$. Consistent with economic voting theory, this effect is positive. As a result, the model does provide some support for the idea that economic growth affects whether individual voters decide to support the incumbent party or not. Note, however, that this effect is small. As few economic voting studies match aggregate economic statistics to individual voting intention data, it is hard to know whether this effect is usual. But we can rule out that 

A series of robustness tests do show

First, GDP change where $t = 0$ is positive. This is consistent with economic voting theory and implies that economic growth does affect whether voters decide to support the incumbent party. Note, however, that the effect is small. What's more, this small effect persists

Isn't a product of estimating GDP change where no time has passed. Even a model that estimates year-on-year GDP change (whether using the estimated daily GDP or the raw monthly estimates) shows effects of X, consistent with this model.


Table 1 shows the resulting parameter estimates from the fitted model. Here, each coefficient is in the expected direction. GDP change at $t = 0$ is small, but positive. The decay constant, $\lambda$, is also positive, indicating that the economic voting effect undergoes exponential decay consistent with voter myopia. As the costs of governing literature would have us believe, incumbent voting decays over time. And voters were more inclined to vote for Gordon Brown and David Cameron than Tony Blair, to varying extents.

\input{_assets/table1.tex}

```{r real-decay-plot, fig.cap = paste("The economic vote diminishes as the time interval between the survey and reference date increases. At a time interval of", round(median(pars$halflife), 2), "years, the economic voting effect decays to half of its initial value. Here light, medium, and dark areas reflect 95%, 80%, and 50% credible intervals, respectively."), fig.width = 6, fig.height = 3.7, echo = F}
real_decay_plot
```

Figure \@ref(fig:real-decay-plot) shows how the economic vote diminishes as voters' time horizons increase. At $t = 0$, GDP change has the same effect as shown in table 1. As $t$ gets larger and larger, the economic voting effect gets smaller and smaller until it finally reaches zero. We can use the equation shown above to convert between the decay constant, $\lambda$, and the parameter's half-life, $t_{1/2}$. As a reminder, the latter reflects the amount of time that it takes for the economic voting effect to fall to half of its initial value. Doing so shows that the half-life of the economic vote is around `r round(median(half_life_dist), 2)` years (95% CI = `r round(quantile(half_life_dist, 0.025), 2)` to `r round(quantile(half_life_dist, 0.975), 2)`)^[Note that this figure is computed by transforming the entire posterior distribution of the decay constant, $\lambda$, and then taking its median and not simply transforming the point estimate shown in table 1. As such, there may be a small discrepancy between the two.]. That is to say, were voters to compare the state of the economy now to the state of the economy `r round(median(half_life_dist), 2)` years ago, we would expect the effect to be half the size of the effect where they simply considered the state of the economy in the present moment.

Note how that as the economic voting effect *diminishes*, our certainty about its true value actually *increases*. This might seem unusual: why should we be any more certain about the effect of GDP growth over five years than over, say, one year or even one month? To see why, reflect on what we know about exponential decay. Under this process, we start with some initial quantity that we expect to deplete over time. Eventually, the quantity will fall to such a low amount that it is, for all intents and purposes, equal to zero. Here, we also have to estimate the initial quantity, as it is a parameter and not a substance that we can simply measure with a scale or ruler. Even so, no matter the estimate that we arrive at, we know that it will always equal in the limit where $t$ approaches $\infty$ if it exhibits exponential decay. As a result, we therefore know that as $t$ increases, the parameter is more likely to be closer to zero.

```{r real-slope-plot, fig.cap = paste0("At t = 0, the economic vote has a reasonably-large effect on the probability of voting for the incumbent. ", "After ", round(median(half_life_dist), 2), " years, it is only very small. And after 5 years, it is practically-equivalent to zero."), fig.width = 6, fig.height = 2.3, echo = F}
real_slope_plot
```

Figure \@ref(fig:real-slope-plot) shows how voter myopia shapes the effect of GDP change on the probability of voting for the incumbent party.

\pagebreak


# Discussion and Conclusion

Recency is a real concern: current economic conditions matter more. While that raises the problem that voters might vote for the best manipulator and not the best manager, voters' time horizons do look to be long enough that historic performance matters.

For governments: more evidence that they should stack bad economic news at the start of the session.

Another possibility is that some types of economic change linger longer than others. Downturns seem an obvious example. 

That said, economic voting effects here are quite weak. Hard to contrast to other figures as most economic voting research relies on economic perceptions (which suffer all sorts of bias) or, where they do use economic statistics do so at the aggregate level.

Another possibility is that some types of economic change linger longer than others. @fieldhouse2020, for example, argue that British politics felts the effects of the 2008 global financial crisis much longer than

If past events matter less because voters are not attentive to them, then we might expect the half-life of the economic voting effect to also vary according to the attention that voters pay to politics. More attentive voters might also have greater time frames.

\pagebreak


# References

::: {#refs}
:::
